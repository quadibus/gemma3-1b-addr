{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e82c61-8e5b-475b-81ac-a4c95822b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut c'est moi\n"
     ]
    }
   ],
   "source": [
    "print(\"salut c'est moi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14d25d8-7362-44b5-a684-b8a4c11920d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(environ({'SHELL': '/bin/bash', 'NV_LIBCUBLAS_VERSION': '12.4.5.8-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'KUBERNETES_SERVICE_PORT_HTTPS': '443', 'NV_NVML_DEV_VERSION': '12.4.127-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn9-cuda-12', 'KUBERNETES_SERVICE_PORT': '443', 'AWS_S3_ENDPOINT': 'minio.lab.sspcloud.fr', 'WORKSPACE_DIR': '/home/onyxia/work', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.21.5-1+cuda12.4', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.21.5-1', 'HOSTNAME': 'jupyter-python-gpu-901276-0', 'PYTHON_VERSION': '3.12.9', 'GIT_USER_MAIL': 'adrien.quentin@insee.fr', 'DARK_MODE': 'true', 'NVIDIA_REQUIRE_CUDA': 'cuda>=12.4 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 brand=tesla,driver>=535,driver<536 brand=unknown,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=geforce,driver>=535,driver<536 brand=geforcertx,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=titan,driver>=535,driver<536 brand=titanrtx,driver>=535,driver<536', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-12-4=12.4.5.8-1', 'ROOT_PROJECT_DIRECTORY': '/home/onyxia/work', 'NV_NVTX_VERSION': '12.4.127-1', 'PROJECT_USER': 'onyxia', 'GIT_REPOSITORY': '', 'AWS_DEFAULT_REGION': 'us-east-1', 'MC_HOST_s3': 'https://9NM4O4ZS0V6J9BZIDSKH:sgIBo0qedpM6pB0rYUJjtpGxuAHqFaG+SC+lmsQ+:eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiI5Tk00TzRaUzBWNko5QlpJRFNLSCIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzQzNjYyMDIzLCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6ImFkcmllbi5xdWVudGluQGluc2VlLmZyIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImV4cCI6MTc0NDI3MDU2OCwiZmFtaWx5X25hbWUiOiJRdWVudGluIiwiZ2l2ZW5fbmFtZSI6IkFkcmllbiIsImdyb3VwcyI6WyJVU0VSX09OWVhJQSJdLCJpYXQiOjE3NDM2NjU3NjgsImlzcyI6Imh0dHBzOi8vYXV0aC5sYWIuc3NwY2xvdWQuZnIvYXV0aC9yZWFsbXMvc3NwY2xvdWQiLCJqdGkiOiJiMzU0ZjE5My00YTVkLTRlYjEtOTdjOC1mZDE2Yzk4ZmM1ZjQiLCJuYW1lIjoiQWRyaWVuIFF1ZW50aW4iLCJwb2xpY3kiOiJzdHNvbmx5IiwicHJlZmVycmVkX3VzZXJuYW1lIjoicXVhZCIsInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwidW1hX2F1dGhvcml6YXRpb24iLCJkZWZhdWx0LXJvbGVzLXNzcGNsb3VkIl0sInNjb3BlIjoib3BlbmlkIHByb2ZpbGUgZ3JvdXBzIGVtYWlsIiwic2lkIjoiOTdkNDk1ZDEtZmZkZS00OThlLWFlZDYtNzYzOTk0ZDVhOTI1Iiwic3ViIjoiZWRkZTgxYTQtZWE3MS00YjgzLWJmMDQtMGIxNTBkNDkxNjBlIiwidHlwIjoiQmVhcmVyIn0.iLlvro25l6hklRiB3ZyygztkCuvubhOzPgLfUvnAx8gBQcZYVYJqSQDc41GFKLYFb4Ts_Fs_lE_cn2fJEdmr1g@minio.lab.sspcloud.fr', 'NV_CUDA_CUDART_DEV_VERSION': '12.4.127-1', 'NV_LIBCUSPARSE_VERSION': '12.3.1.170-1', 'NV_LIBNPP_VERSION': '12.2.5.30-1', 'PROJECT_GROUP': 'users', 'NCCL_VERSION': '2.21.5-1', 'AWS_WORKING_DIRECTORY_PATH': 'quad/', 'VAULT_TOKEN': 'hvs.CAESIP3SrDMzmQzF8LXF7oNPKKin_EXYwrrqis7puK34fkVyGh4KHGh2cy5lcE1ibVdXdDFsdnppb3dxTzJZZ3hyR2E', 'PWD': '/home/onyxia/work', 'VAULT_TOP_DIR': 'quad', 'NV_CUDNN_PACKAGE': 'libcudnn9-cuda-12=9.1.0.70-1', 'S3_ENDPOINT': 'https://minio.lab.sspcloud.fr/', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'VAULT_MOUNT': 'onyxia-kv', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-12-4=12.4.127-1', 'NV_LIBNPP_PACKAGE': 'libnpp-12-4=12.2.5.30-1', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'VAULT_RELATIVE_PATH': '', 'NV_LIBCUBLAS_DEV_VERSION': '12.4.5.8-1', 'NVIDIA_PRODUCT_NAME': 'CUDA', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-12-4', 'NV_CUDA_CUDART_VERSION': '12.4.127-1', 'HOME': '/home/onyxia', 'USERNAME': 'onyxia', 'LANG': 'en_US.UTF-8', 'KUBERNETES_PORT_443_TCP': 'tcp://10.233.0.1:443', 'KUBERNETES_NAMESPACE': 'user-quad', 'CUDA_VERSION': '12.4.1', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-12-4=12.4.5.8-1', 'NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE': 'cuda-nsight-compute-12-4=12.4.1-1', 'AWS_SECRET_ACCESS_KEY': 'sgIBo0qedpM6pB0rYUJjtpGxuAHqFaG+SC+lmsQ+', 'IMAGE_NAME': 'inseefrlab/onyxia-jupyter-python:py3.12.9-gpu', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-12-4=12.2.5.30-1', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-12-4', 'GIT_USER_NAME': 'quad', 'PASSWORD': 'rvyw72tq28r2jzh15eip', 'NV_LIBNPP_DEV_VERSION': '12.2.5.30-1', 'NV_LIBCUSPARSE_DEV_VERSION': '12.3.1.170-1', 'VAULT_ADDR': 'https://vault.lab.sspcloud.fr', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_CUDNN_VERSION': '9.1.0.70-1', 'GID': '100', 'SHLVL': '0', 'GIT_CREDENTIALS_CACHE_DURATION': '0', 'CONDA_DIR': '/opt/conda', 'AWS_ACCESS_KEY_ID': '9NM4O4ZS0V6J9BZIDSKH', 'NV_CUDA_LIB_VERSION': '12.4.1-1', 'NVARCH': 'x86_64', 'KUBERNETES_PORT_443_TCP_PROTO': 'tcp', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn9-dev-cuda-12=9.1.0.70-1', 'KUBERNETES_PORT_443_TCP_ADDR': '10.233.0.1', 'GROUPNAME': 'users', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-12-4', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.21.5-1+cuda12.4', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'GIT_PERSONAL_ACCESS_TOKEN': '', 'NV_CUDA_NSIGHT_COMPUTE_VERSION': '12.4.1-1', 'KUBERNETES_POD_NAME': 'jupyter-python-gpu-901276-0', 'NB_USER': 'onyxia', 'KUBERNETES_SERVICE_HOST': '10.233.0.1', 'NV_NVPROF_VERSION': '12.4.127-1', 'LC_ALL': 'en_US.UTF-8', 'KUBERNETES_PORT': 'tcp://10.233.0.1:443', 'KUBERNETES_PORT_443_TCP_PORT': '443', 'PATH': '/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/onyxia/.local/bin:/home/onyxia/.krew/bin', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'AWS_SESSION_TOKEN': 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiI5Tk00TzRaUzBWNko5QlpJRFNLSCIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNzQzNjYyMDIzLCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6ImFkcmllbi5xdWVudGluQGluc2VlLmZyIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImV4cCI6MTc0NDI3MDU2OCwiZmFtaWx5X25hbWUiOiJRdWVudGluIiwiZ2l2ZW5fbmFtZSI6IkFkcmllbiIsImdyb3VwcyI6WyJVU0VSX09OWVhJQSJdLCJpYXQiOjE3NDM2NjU3NjgsImlzcyI6Imh0dHBzOi8vYXV0aC5sYWIuc3NwY2xvdWQuZnIvYXV0aC9yZWFsbXMvc3NwY2xvdWQiLCJqdGkiOiJiMzU0ZjE5My00YTVkLTRlYjEtOTdjOC1mZDE2Yzk4ZmM1ZjQiLCJuYW1lIjoiQWRyaWVuIFF1ZW50aW4iLCJwb2xpY3kiOiJzdHNvbmx5IiwicHJlZmVycmVkX3VzZXJuYW1lIjoicXVhZCIsInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1zc3BjbG91ZCJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwidW1hX2F1dGhvcml6YXRpb24iLCJkZWZhdWx0LXJvbGVzLXNzcGNsb3VkIl0sInNjb3BlIjoib3BlbmlkIHByb2ZpbGUgZ3JvdXBzIGVtYWlsIiwic2lkIjoiOTdkNDk1ZDEtZmZkZS00OThlLWFlZDYtNzYzOTk0ZDVhOTI1Iiwic3ViIjoiZWRkZTgxYTQtZWE3MS00YjgzLWJmMDQtMGIxNTBkNDkxNjBlIiwidHlwIjoiQmVhcmVyIn0.iLlvro25l6hklRiB3ZyygztkCuvubhOzPgLfUvnAx8gBQcZYVYJqSQDc41GFKLYFb4Ts_Fs_lE_cn2fJEdmr1g', 'NV_LIBNCCL_PACKAGE_VERSION': '2.21.5-1', 'GIT_BRANCH': '', 'KUBERNETES_SERVICE_ACCOUNT': 'jupyter-python-gpu-901276', 'UID': '1000', 'DEBIAN_FRONTEND': 'noninteractive', 'AWS_PATH_STYLE_ACCESS': 'true', 'GIT_PYTHON_REFRESH': 'quiet', 'JPY_SESSION_NAME': '/home/onyxia/work/gemma3-1b-addr/gemma3-1b-addr.ipynb', 'JPY_PARENT_PID': '42', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'python', 'PYTORCH_CUDA_ALLOC_CONF': 'expandable_segments:True,roundup_power2_divisions:[32:256,64:128,256:64,>:32]', 'HF_HUB_ENABLE_HF_TRANSFER': '1', 'UNSLOTH_IS_PRESENT': '1', 'CUDA_MODULE_LOADING': 'LAZY', 'UNSLOTH_ZOO_IS_PRESENT': '1', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'UNSLOTH_PATCHED': '1', 'TORCHINDUCTOR_FX_GRAPH_CACHE': '1', 'TORCHINDUCTOR_AUTOTUNE_REMOTE_CACHE': '1', 'ENABLE_AOT_AUTOGRAD_CACHE': '1', 'TORCHINDUCTOR_CACHE_DIR': '/tmp/torchinductor_onyxia', 'UNSLOTH_IGNORED_TOKENIZER_NAMES': 'unsloth/qwen2.5-coder-7b-instruct\\nunsloth/qwen2.5-coder-1.5b-instruct-bnb-4bit\\nunsloth/qwen2.5-coder-1.5b-instruct\\nunsloth/qwen2.5-coder-7b-instruct-bnb-4bit', 'RAY_CLIENT_MODE': '0', 'NCCL_CUMEM_ENABLE': '0', 'TORCHINDUCTOR_COMPILE_THREADS': '1', 'UNSLOTH_FORCE_FLOAT32': '1', 'UNSLOTH_RETURN_LOGITS': '0', 'UNSLOTH_FULLGRAPH': '1', 'UNSLOTH_USE_NEW_MODEL': '1', 'UNSLOTH_ENABLE_FULL_FINETUNING': '0', 'UNSLOTH_MIXED_PRECISION': 'float32'}))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.keys())\n",
    "\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    !pip install --no-deps unsloth vllm\n",
    "# Install latest Hugging Face for Gemma-3!\n",
    "!pip install --no-deps git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d72bbb-5034-450e-a1d4-3d92ae830aa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsloth: You already added LoRA adapters to your model!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mFastModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinetune_vision_layers\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Turn off for just text!\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinetune_language_layers\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Should leave on!\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinetune_attention_modules\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Attention good for GRPO\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinetune_mlp_modules\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# SHould leave on always!\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Larger = higher accuracy, but might overfit\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_alpha\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Recommended alpha == r at least\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3407\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/unsloth/models/vision.py:487\u001b[39m, in \u001b[36mFastBaseModel.get_peft_model\u001b[39m\u001b[34m(model, r, target_modules, lora_alpha, lora_dropout, bias, finetune_vision_layers, finetune_language_layers, finetune_attention_modules, finetune_mlp_modules, layers_to_transform, layers_pattern, use_gradient_checkpointing, random_state, max_seq_length, use_rslora, modules_to_save, init_lora_weights, loftq_config, temporary_location, **kwargs)\u001b[39m\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Rank of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(r)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be larger than 0.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, PeftModelForCausalLM):\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth: You already added LoRA adapters to your model!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_modules == \u001b[33m\"\u001b[39m\u001b[33mall-linear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    490\u001b[39m     finetune_vision_layers     = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsloth: You already added LoRA adapters to your model!"
     ]
    }
   ],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = True,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "878de234-bb31-4550-9134-5e8bf4e8ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Gemma3 patching. Transformers: 4.50.0.dev0. vLLM: 0.8.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.568 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length = max_seq_length, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e902e7aa-825d-4e56-9a53-7bf8dcb404fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2695 examples [00:00, 31003.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Address': 'Supermarch√© Carrefour, 147 Rue de Rivoli, 75001 Paris, France', 'Building_Number': 147, 'City': 'Paris', 'Recipient': 'Supermarch√© Carrefour', 'Street_Name_old': 'Rue de Rivoli', 'Street_Name': 'de Rivoli', 'type_voie': 'Rue', 'Zip_Code': 75001, 'Country': 'France', 'repetition': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Address', 'Building_Number', 'City', 'Recipient', 'Street_Name_old', 'Street_Name', 'type_voie', 'Zip_Code', 'Country', 'repetition'],\n",
       "    num_rows: 2695\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load CSV into Hugging Face dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"fr-train-dataset2.csv\")\n",
    "\n",
    "# Access the split (train by default)\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Preview\n",
    "print(train_dataset[0])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d855e76-6dc8-4131-8cd8-6824550eecd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supermarch√© Carrefour, 147 Rue de Rivoli, 75001 Paris, France'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"Address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3b2779-19e0-4fef-853b-64bf6e743488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2695/2695 [00:01<00:00, 2261.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Address': 'Supermarch√© Carrefour, 147 Rue de Rivoli, 75001 Paris, France', 'Building_Number': 147, 'City': 'Paris', 'Recipient': 'Supermarch√© Carrefour', 'Street_Name_old': 'Rue de Rivoli', 'Street_Name': 'de Rivoli', 'type_voie': 'Rue', 'Zip_Code': 75001, 'Country': 'France', 'repetition': None, 'question': 'Supermarch√© Carrefour, 147 Rue de Rivoli, 75001 Paris, France', 'answer': {'Building_Number': 147, 'City': 'Paris', 'Country': 'France', 'Recipient': 'Supermarch√© Carrefour', 'Street_Name': 'de Rivoli', 'Zip_Code': 75001, 'repetition': None, 'type_voie': 'Rue'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define columns to exclude from tgt\n",
    "exclude_cols = [\"Address\", \"Street_Name_old\"]  # üëà Add any column to ignore here\n",
    "\n",
    "# Determine tgt columns\n",
    "tgt_cols = [col for col in train_dataset.column_names if col not in exclude_cols]\n",
    "src_col = \"Address\"\n",
    "\n",
    "\n",
    "# Transform\n",
    "def transform(example):\n",
    "    return {\n",
    "        \"question\": example[src_col],\n",
    "        \"answer\": {col: example[col] for col in tgt_cols}\n",
    "    }\n",
    "\n",
    "dataset_refined = train_dataset.map(transform)\n",
    "\n",
    "# Preview\n",
    "print(dataset_refined[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad49ff07-dec4-42a9-843e-17fc098b4eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Building_Number': 147,\n",
       " 'City': 'Paris',\n",
       " 'Country': 'France',\n",
       " 'Recipient': 'Supermarch√© Carrefour',\n",
       " 'Street_Name': 'de Rivoli',\n",
       " 'Zip_Code': 75001,\n",
       " 'repetition': None,\n",
       " 'type_voie': 'Rue'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_refined[0][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c89a462-74d7-488e-b459-fabf96d4a4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supermarch√© Carrefour, 147 Rue de Rivoli, 75001 Paris, France'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_refined[0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c5e0b-5989-405a-b4ce-031e43566312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
