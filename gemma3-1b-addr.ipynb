{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d25d8-7362-44b5-a684-b8a4c11920d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    !pip install --no-deps unsloth vllm\n",
    "# Install latest Hugging Face for Gemma-3!\n",
    "!pip install --no-deps git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878de234-bb31-4550-9134-5e8bf4e8ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length = max_seq_length, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d72bbb-5034-450e-a1d4-3d92ae830aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = True,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902e7aa-825d-4e56-9a53-7bf8dcb404fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load CSV into Hugging Face dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"/content/fr-train-dataset2.csv\")\n",
    "\n",
    "# Access the split (train by default)\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Preview\n",
    "print(train_dataset[0])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d855e76-6dc8-4131-8cd8-6824550eecd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
