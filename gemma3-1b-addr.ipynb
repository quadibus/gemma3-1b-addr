{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd37b96-43ec-4713-9336-9136ce7b999e",
   "metadata": {},
   "source": [
    "# installation dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d1d20-6537-4ff7-bfa0-7efbada78d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.keys())\n",
    "\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    !pip install --no-deps unsloth vllm\n",
    "# Install latest Hugging Face for Gemma-3!\n",
    "!pip install --no-deps git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475ef86-e31c-45e2-b9c2-5292e7d38754",
   "metadata": {},
   "source": [
    "# configuration du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3f7b0-0186-4ec7-a073-a0be0d006415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-1b-pt-unsloth-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d72bbb-5034-450e-a1d4-3d92ae830aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = False,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902e7aa-825d-4e56-9a53-7bf8dcb404fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load CSV into Hugging Face dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"fr-train-dataset2.csv\")\n",
    "\n",
    "# Access the split (train by default)\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Preview\n",
    "print(train_dataset[0])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d855e76-6dc8-4131-8cd8-6824550eecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][\"Address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b2779-19e0-4fef-853b-64bf6e743488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to exclude from tgt\n",
    "exclude_cols = [\"Address\", \"Street_Name_old\"]  # ðŸ‘ˆ Add any column to ignore here\n",
    "\n",
    "# Determine tgt columns\n",
    "tgt_cols = [col for col in train_dataset.column_names if col not in exclude_cols]\n",
    "src_col = \"Address\"\n",
    "\n",
    "\n",
    "# Transform\n",
    "def transform(example):\n",
    "    return {\n",
    "        \"question\": example[src_col],\n",
    "        \"answer\": {col: example[col] for col in tgt_cols}\n",
    "    }\n",
    "\n",
    "dataset_refined = train_dataset.map(transform)\n",
    "\n",
    "\n",
    "# Preview\n",
    "print(dataset_refined[0])\n",
    "\n",
    "\n",
    "print(dataset_refined.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49ff07-dec4-42a9-843e-17fc098b4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_refined[0][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89a462-74d7-488e-b459-fabf96d4a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_refined[0][\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dad3f2-8bc8-491e-9014-a1da0f6e3c4d",
   "metadata": {},
   "source": [
    "# configuration de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df6f3f-737d-491b-afe7-dd62823a543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_example(example):\n",
    "    return {\n",
    "        \"text\": f\"Adresse : {example['question']}\\nChamps : {json.dumps(example['answer'], ensure_ascii=False)}\"\n",
    "    }\n",
    "\n",
    "formatted_dataset = dataset_refined.map(format_example)\n",
    "formatted_dataset = formatted_dataset.remove_columns(\n",
    "    [col for col in formatted_dataset.column_names if col != \"text\"]\n",
    ")\n",
    "\n",
    "print(formatted_dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d425280-2775-422b-84aa-961b91574e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=formatted_dataset,\n",
    "    args=SFTConfig(\n",
    "        max_seq_length=1024,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        max_steps=30,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1b020-dfa6-46da-af09-9fa5b835244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(trainer.train_dataset[100][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a4d7-c0f0-45dd-bdf7-c6446891ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed72b77-d33f-4e4d-a06d-844dc5230bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"gemma3-address-parser\")\n",
    "model.save_pretrained(\"gemma3-address-parser\") \n",
    "tokenizer.save_pretrained(\"gemma3-address-parser\")\n",
    "model.config.save_pretrained(\"gemma3-address-parser\")\n",
    "\n",
    "model.save_pretrained_gguf(\n",
    "        \"gemma3-address-parser\",\n",
    "        quantization_type = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c00f65-f010-4df7-8ad6-fa9a7aaf5606",
   "metadata": {},
   "source": [
    "# run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8ad27-b839-4c31-86a7-64a036ad0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gemma3-address-parser\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gemma3-address-parser\", torch_dtype=torch.float16).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab4059-ecca-4c80-83ed-03afd1851ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"Leclerc, 10 avenue Victor Hugo, 92200 Neuilly-sur-Seine\"\n",
    "\n",
    "prompt = f\"Adresse : {address}\\nChamps :\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=64,\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3b4a5-d1d0-44e5-9a54-bb2a108b765d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
